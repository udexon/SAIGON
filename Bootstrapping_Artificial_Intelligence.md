## Bootstrapping Artificial Intelligence: Grounding and Metaprogramming
### Graph Machine: A Unified Graph Theoretic Model for Narrow Artificial Intelligence and Artificial General Intelligenec


Yampolskiy (2018) gave a comprehensive review on ...

Our hypothesis: bottleneck in AGI was due to lack of knowledge in Stack Machine, reverse polish notation, graph theory, graph database (4 areas, discuss in depths).

We introduce the concept of a "graph machine", a graph comprising both data and code, and is therefore capable of evaluating itself, as model of the human mind. In practice, in order for the graph machine to be able to analyze its own code, it needs to be implemented using a homoiconic programming language. We have implemented a version of the reverse Polish notation, similar to the Forth programming language, called 5GL (the Fifth Generation Graph Language, partly as a pun to Forth).

One of the important breakthroughs in our investigation concerns the application of graph isomorphism to the input and output of a computer program function.

To put it simply, graph isomorphism simply means to compare if two graphs are “similar”. Of these properties, the number of nodes of a graph is the simplest measure of isomorphism. This operation conveniently divides computer program functions into database related and otherwise. In general, database functions increase the number of nodes in a graph (although we may use database functions to delete nodes in a graph). In contrast to this, most data processing functions take in a large array of numbers (represented as nodes of a graph) and transform them into a smaller set of array, thus reducing the number of nodes in the graph. The underlying principle is that we represent the knowledge of an individual human being as a graph, which is the most one of the most fundamental and flexible constructs in mathematics.

Further, Narrow AI can be categorized as node reducing functions (NF-). Database functions include node adding functions (NF+) (delete node is of course trivial). We choose the acronyms NF+ instead of NAF for Node Adding Functions to avoid confusion with the acronym of NAI (narrow Artificial Intelligence). Because of the choice of NF+, we use NF- to denote node reducing functions.

If NAI are node reducing functions (NF-), then there have to be node adding functions (NF+) to construct a graph machine that mimics the human mind. Otherwise there will not be functions that can increase the number of nodes in the graph machine, which will cause it to fail, as NF- would have no input data, which are equivalent to large number of nodes, to operate on. 

:: Add these points to make complete introduction:

- Gounding using graph database, integrate Unix file system, program code as database object

- Analyze RPN program, homoiconicity, self evaluating, self awareness

- Cloudias, easy to learn, everyone can program AI.


was:: SAIGON: A Unified Graph Theoretic Model for Narrow Artificial Intelligence and Artificial General Intelligenec
was:: ? 5AIGON? SAIGON or
:: Saigon notes notation


One most crucial factor: Homoiconicity -- program can be analyse as data, due to its simple structure. 99% or more of existing programs are NOT homoiconic. Knowledge of homoiconicity is rare. Too rare. Even Forth programmers are not concerned about this issue. Also needs a graph database that incorporates file system and the self program source code, and and sensor and Internet, external data.

Proof: Human language is homoiconic; Stack machine is simplest machine; Human brain could operate like a stack machine -- which is conceived by human brain; Try to prove it, contrary or otherwise, proving process will show truth.

We propose modifications to the Turing Test based on techniques derived from graph theory. More specifically, 

(i) Turing Test is generalized to a suite of enumerable tests, i.e. Enumerated Turing Tests.

(ii) A graph database model is proposed to represent and implement the enumerated Turing Tests.

(iii) The proposed graph database is homoiconic and self evaluating, comprising not only knowledge and goals, but also functions or code to satisfy given goals, based on stack machine architecture.

We believe our approach satisfies 
the principle of Occam's razor, as it does not require exotic theories to model AI ranging from Narrow AI to AGI. 

Occam's razor also implies that, by making efforts or tests to change its conditions, a different outcome may be achieved. Since Occam's razor requires least effort, therefore the effort invested to change the outcome will also be minimal. In this case, the parameter to measure will be the number of programmers who understand SAIGON, versus the output they can produce towards achieving AGI, measurable on a monthly basis.

Further, we outline a practical plan to achieve AGI within finite time using finite resources, which we believe to be an unprecedented proposal.

The adventure to find the secret recipes of AGI is perhaps unprecedented in mankind's history. The closest analogy is perhaps the invention of the transistor, which ushered in the age of electronics. The biggest difference is that, the number of researchers and programmers capable of making the breakthrough in AGI is much larger than those during the the invention of the transistor. As such, it may seem odd that AGI formula is NOT discovered sooner. 


Yampolskiy, R. V. (2018). Why We Do Not Evolve Software? Analysis of Evolutionary Algorithms. Evolutionary Bioinformatics, 14, 1176934318815906. https://doi.org/10.1177%2F1176934318815906
